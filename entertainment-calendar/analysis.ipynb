{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c2309fc",
   "metadata": {},
   "source": [
    "## Join Two tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2fb9f8c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import re\n",
    "from tika import parser\n",
    "import dateutil.parser\n",
    "import json\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85674583",
   "metadata": {},
   "source": [
    "* Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7f3402a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95000 entries, 0 to 94999\n",
      "Data columns (total 43 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Unnamed: 0              95000 non-null  int64  \n",
      " 1   Story Primary ID        95000 non-null  int64  \n",
      " 2   Story ID                95000 non-null  object \n",
      " 3   User Primary ID         95000 non-null  int64  \n",
      " 4   User ID                 95000 non-null  object \n",
      " 5   Gender                  44938 non-null  object \n",
      " 6   Age                     95000 non-null  int64  \n",
      " 7   Title                   93895 non-null  object \n",
      " 8   Narrative               93727 non-null  object \n",
      " 9   Media                   95000 non-null  object \n",
      " 10  Account Created Date    95000 non-null  object \n",
      " 11  Interest                95000 non-null  object \n",
      " 12  sport_event             87011 non-null  object \n",
      " 13  festival                73024 non-null  object \n",
      " 14  hate_flag               95000 non-null  int64  \n",
      " 15  sarc_flag               93509 non-null  float64\n",
      " 16  Country                 28981 non-null  object \n",
      " 17  CONTINENT               28981 non-null  object \n",
      " 18  geometry                28981 non-null  object \n",
      " 19  Song                    9346 non-null   object \n",
      " 20  singer                  9346 non-null   object \n",
      " 21  rank                    9346 non-null   float64\n",
      " 22  year                    9346 non-null   float64\n",
      " 23  movie_title             1287 non-null   object \n",
      " 24  movie_year              1287 non-null   float64\n",
      " 25  movie_rank              1287 non-null   float64\n",
      " 26  release_date            1287 non-null   object \n",
      " 27  Google_Lang_ID          92392 non-null  object \n",
      " 28  Tika_Lang_ID            94984 non-null  object \n",
      " 29  image_caption           83515 non-null  object \n",
      " 30  image_objects           83514 non-null  object \n",
      " 31  langdetect_code         95000 non-null  object \n",
      " 32  tika_code               94604 non-null  object \n",
      " 33  translated_titles       95000 non-null  object \n",
      " 34  translated_narratives   95000 non-null  object \n",
      " 35  Geographic Information  95000 non-null  object \n",
      " 36  toxicity                95000 non-null  float64\n",
      " 37  severe_toxicity         95000 non-null  float64\n",
      " 38  obscene                 95000 non-null  float64\n",
      " 39  identity_attack         95000 non-null  float64\n",
      " 40  insult                  95000 non-null  float64\n",
      " 41  threat                  95000 non-null  float64\n",
      " 42  sexual_explicit         95000 non-null  float64\n",
      "dtypes: float64(12), int64(5), object(26)\n",
      "memory usage: 31.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Creating our combined csv file\n",
    "blogs_file = 'tsv_pixstory_hw2.tsv'\n",
    "# src_data_df = pd.read_csv(src_file, sep='\\t')\n",
    "chunk_test = pd.read_csv(blogs_file, sep='\\t', chunksize=1000)\n",
    "test_df = pd.concat(chunk_test)\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a0178164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  1000\n",
      "Processing  2000\n",
      "Processing  3000\n",
      "Processing  4000\n",
      "Processing  5000\n",
      "Processing  6000\n",
      "Processing  7000\n",
      "Processing  8000\n",
      "Processing  9000\n",
      "Processing  10000\n",
      "Processing  11000\n",
      "Processing  12000\n",
      "Processing  13000\n",
      "Processing  14000\n",
      "Processing  15000\n",
      "Processing  16000\n",
      "Processing  17000\n",
      "Processing  18000\n",
      "Processing  19000\n",
      "Processing  20000\n",
      "Processing  21000\n",
      "Processing  22000\n",
      "Processing  23000\n",
      "Processing  24000\n",
      "Processing  25000\n",
      "Processing  26000\n",
      "Processing  27000\n",
      "Processing  28000\n",
      "Processing  29000\n",
      "Processing  30000\n",
      "Processing  31000\n",
      "Processing  32000\n",
      "Processing  33000\n",
      "Processing  34000\n",
      "Processing  35000\n",
      "Processing  36000\n",
      "Processing  37000\n",
      "Processing  38000\n",
      "Processing  39000\n",
      "Processing  40000\n",
      "Processing  41000\n",
      "Processing  42000\n",
      "Processing  43000\n",
      "Processing  44000\n",
      "Processing  45000\n",
      "Processing  46000\n",
      "Processing  47000\n",
      "Processing  48000\n",
      "Processing  49000\n",
      "Processing  50000\n",
      "Processing  51000\n",
      "Processing  52000\n",
      "Processing  53000\n",
      "Processing  54000\n",
      "Processing  55000\n",
      "Processing  56000\n",
      "Processing  57000\n",
      "Processing  58000\n",
      "Processing  59000\n",
      "Processing  60000\n",
      "Processing  61000\n",
      "Processing  62000\n",
      "Processing  63000\n",
      "Processing  64000\n",
      "Processing  65000\n",
      "Processing  66000\n",
      "Processing  67000\n",
      "Processing  68000\n",
      "Processing  69000\n",
      "Processing  70000\n",
      "Processing  71000\n",
      "Processing  72000\n",
      "Processing  73000\n",
      "Processing  74000\n",
      "Processing  75000\n",
      "Processing  76000\n",
      "Processing  77000\n",
      "Processing  78000\n",
      "Processing  79000\n",
      "Processing  80000\n",
      "Processing  81000\n",
      "Processing  82000\n",
      "Processing  83000\n",
      "Processing  84000\n",
      "Processing  85000\n",
      "Processing  86000\n",
      "Processing  87000\n",
      "Processing  88000\n",
      "Processing  89000\n",
      "Processing  90000\n",
      "Processing  91000\n",
      "Processing  92000\n",
      "Processing  93000\n",
      "Processing  94000\n",
      "Processing  95000\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "chunksize = 10 ** 3\n",
    "i = 0;\n",
    "q1_data = {}\n",
    "\n",
    "def descrete_age(age):\n",
    "    if int(age) < 18:\n",
    "        return 'Millennial'\n",
    "    elif int(age) < 30:\n",
    "        return 'GenX'\n",
    "    elif int(age) < 50:\n",
    "        return 'Boomer'\n",
    "    elif int(age) < 70:\n",
    "        return 'Silent'\n",
    "    else:\n",
    "        return 'Greatest'\n",
    "    \n",
    "def descrete_time(time_input):\n",
    "    yourdate = dateutil.parser.parse(time_input)\n",
    "    res = f'{yourdate.hour:02d}'\n",
    "#     res = yourdate.hour * 6 + int(yourdate.minute / 10)\n",
    "#     delta = yourdate.hour * 6 + int(yourdate.minute / 10)\n",
    "#     cur_day = datetime.datetime.now() + datetime.timedelta(days=-557 + delta)\n",
    "#     res = cur_day.strftime('%Y-%m-%d')\n",
    "#     print(cur_day.strftime('%Y-%m-%d'))\n",
    "#     print(res)\n",
    "    return res\n",
    "\n",
    "# i = 1\n",
    "# for chunk in pd.read_csv(blogs_file, sep='\\t', chunksize=chunksize):\n",
    "#     for index, row in chunk.iterrows():\n",
    "#         i+=1\n",
    "# print(i)\n",
    "\n",
    "age_type = []\n",
    "time_span = []\n",
    "count = []\n",
    "for chunk in pd.read_csv(blogs_file, sep='\\t', chunksize=chunksize):\n",
    "    for index, row in chunk.iterrows():\n",
    "        cur_age_type = descrete_age(row['Age'])\n",
    "        cur_time_span = descrete_time(row['Account Created Date'])\n",
    "#         print(cur_time_span) \n",
    "        if cur_age_type in q1_data:\n",
    "            if cur_time_span in q1_data[cur_age_type]:\n",
    "                q1_data[cur_age_type][cur_time_span] += 1\n",
    "            else:\n",
    "                q1_data[cur_age_type][cur_time_span] = 1\n",
    "        else:\n",
    "            cur_time_dict = {}\n",
    "            cur_time_dict[cur_time_span] = 1\n",
    "            q1_data[cur_age_type] = cur_time_dict\n",
    "        i += 1\n",
    "        if i%1000==0:\n",
    "            print(\"Processing \", i)\n",
    "\n",
    "\n",
    "age_analysis_jsondata = 'age_analysis_jsondata.json'\n",
    "with open(age_analysis_jsondata, 'w') as fp:\n",
    "    json.dump(q1_data, fp)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b0c1b868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['age_type', 'time_span', 'count'], dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_type = []\n",
    "time_span = []\n",
    "count = []\n",
    "\n",
    "for k, v in q1_data.items():\n",
    "    for sub_k, sub_v in q1_data[k].items():\n",
    "        age_type.append(k)\n",
    "        time_span.append(sub_k)        \n",
    "        count.append(sub_v)\n",
    "\n",
    "print(len(age_type))        \n",
    "\n",
    "df = pd.DataFrame.from_dict({'age_type':age_type, 'time_span':time_span, 'count':count})\n",
    "        \n",
    "df2 = df.sort_values(['age_type', 'time_span'],\n",
    "              ascending = [True, True])\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f571270f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  1000\n",
      "Processing  2000\n",
      "Processing  3000\n",
      "Processing  4000\n",
      "Processing  5000\n",
      "Processing  6000\n",
      "Processing  7000\n",
      "Processing  8000\n",
      "Processing  9000\n",
      "Processing  10000\n",
      "Processing  11000\n",
      "Processing  12000\n",
      "Processing  13000\n",
      "Processing  14000\n",
      "Processing  15000\n",
      "Processing  16000\n",
      "Processing  17000\n",
      "Processing  18000\n",
      "Processing  19000\n",
      "Processing  20000\n",
      "Processing  21000\n",
      "Processing  22000\n",
      "Processing  23000\n",
      "Processing  24000\n",
      "Processing  25000\n",
      "Processing  26000\n",
      "Processing  27000\n",
      "Processing  28000\n",
      "Processing  29000\n",
      "Processing  30000\n",
      "Processing  31000\n",
      "Processing  32000\n",
      "Processing  33000\n",
      "Processing  34000\n",
      "Processing  35000\n",
      "Processing  36000\n",
      "Processing  37000\n",
      "Processing  38000\n",
      "Processing  39000\n",
      "Processing  40000\n",
      "Processing  41000\n",
      "Processing  42000\n",
      "Processing  43000\n",
      "Processing  44000\n",
      "Processing  45000\n",
      "Processing  46000\n",
      "Processing  47000\n",
      "Processing  48000\n",
      "Processing  49000\n",
      "Processing  50000\n",
      "Processing  51000\n",
      "Processing  52000\n",
      "Processing  53000\n",
      "Processing  54000\n",
      "Processing  55000\n",
      "Processing  56000\n",
      "Processing  57000\n",
      "Processing  58000\n",
      "Processing  59000\n",
      "Processing  60000\n",
      "Processing  61000\n",
      "Processing  62000\n",
      "Processing  63000\n",
      "Processing  64000\n",
      "Processing  65000\n",
      "Processing  66000\n",
      "Processing  67000\n",
      "Processing  68000\n",
      "Processing  69000\n",
      "Processing  70000\n",
      "Processing  71000\n",
      "Processing  72000\n",
      "Processing  73000\n",
      "Processing  74000\n",
      "Processing  75000\n",
      "Processing  76000\n",
      "Processing  77000\n",
      "Processing  78000\n",
      "Processing  79000\n",
      "Processing  80000\n",
      "Processing  81000\n",
      "Processing  82000\n",
      "Processing  83000\n",
      "Processing  84000\n",
      "Processing  85000\n",
      "Processing  86000\n",
      "Processing  87000\n",
      "Processing  88000\n",
      "Processing  89000\n",
      "Processing  90000\n",
      "Processing  91000\n",
      "Processing  92000\n",
      "Processing  93000\n",
      "Processing  94000\n",
      "Processing  95000\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import ast\n",
    "chunksize = 10 ** 3\n",
    "i = 0;\n",
    "q2_data = {}\n",
    "  \n",
    "def descrete_time(time_input):\n",
    "    yourdate = dateutil.parser.parse(time_input)\n",
    "#     res = f'{yourdate.hour:02d}'\n",
    "    res = yourdate.strftime('%Y-%m-%d')\n",
    "#     delta = yourdate.hour * 6 + int(yourdate.minute / 10)\n",
    "#     cur_day = datetime.datetime.now() + datetime.timedelta(days=-557 + delta)\n",
    "#     res = cur_day.strftime('%Y-%m-%d')\n",
    "#     print(cur_day.strftime('%Y-%m-%d'))\n",
    "#     print(res)\n",
    "    return res\n",
    "\n",
    "# i = 1\n",
    "# for chunk in pd.read_csv(blogs_file, sep='\\t', chunksize=chunksize):\n",
    "#     for index, row in chunk.iterrows():\n",
    "#         i+=1\n",
    "# print(i)\n",
    "\n",
    "def count(input):\n",
    "    pass\n",
    "    \n",
    "\n",
    "date = []\n",
    "festival = []\n",
    "sport_event = []\n",
    "i=1\n",
    "for chunk in pd.read_csv(blogs_file, sep='\\t', chunksize=chunksize):\n",
    "    for index, row in chunk.iterrows():\n",
    "        cnt_festival = len(ast.literal_eval(row['festival'])) if row['festival'] and str(row['festival'])!= 'nan' else 0\n",
    "        cnt_sport_event = len(ast.literal_eval(row['sport_event'])) if row['sport_event'] and str(row['sport_event'])!= 'nan' else 0        \n",
    "        cnt_overall = cnt_festival + cnt_sport_event\n",
    "        cur_date = descrete_time(row['Account Created Date'])\n",
    "#         print(cur_date, cnt_festival, cnt_sport_event, cnt_festival+cnt_sport_event) \n",
    "        if cur_date in q2_data:\n",
    "            q2_data[cur_date]['festival'] += cnt_festival\n",
    "            q2_data[cur_date]['sport_event'] += cnt_sport_event            \n",
    "        else:\n",
    "            cur_dict = {}\n",
    "            cur_dict['festival'] = cnt_festival\n",
    "            cur_dict['sport_event'] = cnt_sport_event\n",
    "            q2_data[cur_date] = cur_dict\n",
    "        i += 1\n",
    "        if i%1000==0:\n",
    "            print(\"Processing \", i)\n",
    "\n",
    "\n",
    "age_analysis_jsondata = 'sports_event_analysis_jsondata.json'\n",
    "with open(age_analysis_jsondata, 'w') as fp:\n",
    "    json.dump(q2_data, fp)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1d81f93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511\n"
     ]
    }
   ],
   "source": [
    "date = []\n",
    "festival = []\n",
    "sport_event = []\n",
    "\n",
    "for k, v in q2_data.items():    \n",
    "    date.append(k)\n",
    "    festival.append(v['festival'])        \n",
    "    sport_event.append(v['sport_event'])\n",
    "\n",
    "print(len(date))        \n",
    "\n",
    "df = pd.DataFrame.from_dict({'date':date, 'festival':festival, 'sport_event':sport_event})\n",
    "        \n",
    "df2 = df.sort_values(['date'],\n",
    "              ascending = [True])\n",
    "df2.to_csv('sport_event_festival.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b035dc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 511 entries, 430 to 440\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   date         511 non-null    object\n",
      " 1   festival     511 non-null    int64 \n",
      " 2   sport_event  511 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 16.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75513eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}